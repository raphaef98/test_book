[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lectures",
    "section": "",
    "text": "Preface\nOn this html page you will find a collection of the lectures from Digital Literacy I: Coding A SoSe-2023."
  },
  {
    "objectID": "Lecture3.html#introduction-to-numpy",
    "href": "Lecture3.html#introduction-to-numpy",
    "title": "Lecture 3",
    "section": "Introduction to numpy",
    "text": "Introduction to numpy\nNumPy, short for Numerical Python, is one of the most important foundational packages for numerical computing in Python.\n\nVectorized, fast mathematical operations.\nKey features of NumPy is its N-dimensional array object, or ndarray\n\n\nheight = [1.79, 1.85, 1.95, 1.55]\nweight = [70, 80, 85, 65]\n\n#bmi = weight/height**2\n\n\nheight = np.array([1.79, 1.85, 1.95, 1.55])\nweight = np.array([70, 80, 85, 65])\n\nbmi = weight/height**2\nbmi\n\narray([21.84700852, 23.37472608, 22.35371466, 27.05515088])\n\n\n\nMultiple Dimensions\nare handled naturally by numpy, e.g.\n\nhw1 = np.array([height, weight])\nprint(hw1)\nprint(hw1.shape)\nhw2 = hw1.transpose()\nprint(hw2)\nprint(hw2.shape)\n\n[[ 1.79  1.85  1.95  1.55]\n [70.   80.   85.   65.  ]]\n(2, 4)\n[[ 1.79 70.  ]\n [ 1.85 80.  ]\n [ 1.95 85.  ]\n [ 1.55 65.  ]]\n(4, 2)\n\n\n\n\nAccessing array elements\nis similar to lists but allows for multidimensional index:\n\nprint(hw2[0,1])\n\n70.0\n\n\n\nprint(hw2[:,0])\n\n[1.79 1.85 1.95 1.55]\n\n\n\nprint(hw2[0])\n#equivalent to\nprint(hw2[0,:])\n#shape:\nprint(hw2[0].shape)\n\n[ 1.79 70.  ]\n[ 1.79 70.  ]\n(2,)\n\n\nTo select a subset of the rows in a particular order, you can simply pass a list or ndarray of integers specifying the desired order:\n\nprint(hw2[[2,0,1]])\n\n[[ 1.95 85.  ]\n [ 1.79 70.  ]\n [ 1.85 80.  ]]\n\n\nNegative indices\n\nprint(hw2)\nprint(\"Using negative indices selects rows from the end:\")\nprint(hw2[[-2,-1]])\n\n[[ 1.79 70.  ]\n [ 1.85 80.  ]\n [ 1.95 85.  ]\n [ 1.55 65.  ]]\nUsing negative indices selects rows from the end:\n[[ 1.95 85.  ]\n [ 1.55 65.  ]]\n\n\nYou can pass multiple slices just like you can pass multiple indexes:\n\nhw2[:2,:1]\n\narray([[1.79],\n       [1.85]])\n\n\n\nReshaping\n\nnp.arange(32).reshape((8, 4))\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15],\n       [16, 17, 18, 19],\n       [20, 21, 22, 23],\n       [24, 25, 26, 27],\n       [28, 29, 30, 31]])\n\n\n\n\nBoolean indexing\n\nheight_gt_185 = hw2[:,0]&gt;1.85\nprint(height_gt_185)\nprint(hw2[height_gt_185,1])\n\n[False False  True False]\n[85.]\n\n\nnumpy arrays cannot contain elements with different types. If you try to build such a list, some of the elements’ types are changed to end up with a homogeneous list. This is known as type coercion.\n\nprint(np.array([True, 1, 2]))\nprint(np.array([\"True\", 1, 2]))\nprint(np.array([1.3, 1, 2]))\n\n[1 1 2]\n['True' '1' '2']\n[1.3 1.  2. ]\n\n\nLots of extra useful functions!\n\nnp.zeros((2,3))\n#np.ones((2,3))\n\narray([[0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nnp.eye(3)\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\nnp.column_stack([height, weight])\n\narray([[ 1.79, 70.  ],\n       [ 1.85, 80.  ],\n       [ 1.95, 85.  ],\n       [ 1.55, 65.  ]])"
  },
  {
    "objectID": "Lecture3.html#data-summaries-in-numpy",
    "href": "Lecture3.html#data-summaries-in-numpy",
    "title": "Lecture 3",
    "section": "Data Summaries in numpy",
    "text": "Data Summaries in numpy\nWe can compute simple statistics:\n\nprint(np.mean(hw2))\nprint(np.mean(hw2, axis=0))\n\n38.3925\n[ 1.785 75.   ]\n\n\n\nprint(np.unique([1,1,2,1,2,3,2,2,3]))\n\nprint(np.unique([1,1,2,1,2,3,2,2,3], return_counts=True))\n\n[1 2 3]\n(array([1, 2, 3]), array([3, 4, 2], dtype=int64))"
  },
  {
    "objectID": "Lecture3.html#introduction-to-simulating-probabilistic-events",
    "href": "Lecture3.html#introduction-to-simulating-probabilistic-events",
    "title": "Lecture 3",
    "section": "Introduction to Simulating Probabilistic Events",
    "text": "Introduction to Simulating Probabilistic Events\n\nGenerating Data in numpy\nMeet your friends:\n\nnp.random.permutation: Return a random permutation of a sequence, or return a permuted range\nnp.random.integers: Draw random integers from a given low-to-high range\nnp.random.choice: Generates a random sample from a given 1-D array\n\n\n# Do this (new version)\nfrom numpy.random import default_rng\nrng = default_rng()\n\nx= np.arange(10)\nprint(x)\nprint(rng.permutation(x))\nprint(rng.permutation(list('intelligence')))\n\n[0 1 2 3 4 5 6 7 8 9]\n[6 7 9 4 1 0 3 8 2 5]\n['t' 'c' 'n' 'l' 'e' 'n' 'i' 'e' 'e' 'l' 'i' 'g']\n\n\n\nprint(rng.integers(0,10,5))\nprint(rng.integers(0,10,(5,2)))\n\n[7 9 7 9 4]\n[[9 0]\n [8 6]\n [6 7]\n [0 5]\n [1 5]]\n\n\n\nrng.choice(x,4)\n\narray([8, 5, 1, 4])\n\n\n\n\nExamples:\n\nSpotify playlist\nMovie List\n\n\nmovies_list = ['The Godfather', 'The Wizard of Oz', 'Citizen Kane', 'The Shawshank Redemption', 'Pulp Fiction']\n\n# pick a random choice from a list of strings.\nmovie = rng.choice(movies_list,2)\nprint(movie)\n\n['The Shawshank Redemption' 'The Godfather']"
  },
  {
    "objectID": "Lecture3.html#birthday-paradox",
    "href": "Lecture3.html#birthday-paradox",
    "title": "Lecture 3",
    "section": "Birthday “Paradox”",
    "text": "Birthday “Paradox”\nPlease enter your birthday on google drive https://forms.gle/CeqyRZ4QzWRmJFvs9\nHow many people do you think will share a birthday? Would that be a rare, highly unusual event?\n\n'''#!pip install openpyxl\nimport pandas as pd\nimport numpy as np\n\nurl = \"https://docs.google.com/spreadsheets/d/1zo8l6xPKm8EPAobHHJXRKjq9vtOnAegMkg_VAhcZ6kY/edit?usp=sharing\"\ngResponses = pd.read_excel(url)\n#df[\"date_3\"] = pd.to_datetime(df[\"date_3\"])\nprint(gResponses.dtypes)\n#I am not interested in the year, so I am seting it equal to all\ngResponses['birthday'] = gResponses['birthday'].apply(lambda x: x.replace(year = 2000))\ngResponses'''\n\n'#!pip install openpyxl\\nimport pandas as pd\\nimport numpy as np\\n\\nurl = \"https://docs.google.com/spreadsheets/d/1zo8l6xPKm8EPAobHHJXRKjq9vtOnAegMkg_VAhcZ6kY/edit?usp=sharing\"\\ngResponses = pd.read_excel(url)\\n#df[\"date_3\"] = pd.to_datetime(df[\"date_3\"])\\nprint(gResponses.dtypes)\\n#I am not interested in the year, so I am seting it equal to all\\ngResponses[\\'birthday\\'] = gResponses[\\'birthday\\'].apply(lambda x: x.replace(year = 2000))\\ngResponses'\n\n\nHow can we find out how likely it is that across \\(n\\) folks in a room at least two share a birthday?\nHint: can we put our random number generators to task ?\n\n# Can you simulate 25 birthdays?\nfrom numpy.random import default_rng \nrng = default_rng()\n\n\n#initialize it to be the empty list:\nshardBday = []\n\nn = 40\n\nPossibleBDays = np.arange(1,366)\n#now \"draw\" 25 random bDays:\nfor i in range(1000):# is the 1000 an important number ??\n#no it only determines the precision of my estimate !!\n  ran25Bdays = rng.choice(PossibleBDays, n, replace = True)\n  #it is of utmost importance to allow for same birthdays !! \n  #rng.choice(PossibleBDays, 366, replace = False)\n  x , cts = np.unique(ran25Bdays ,return_counts=True)\n  shardBday = np.append(shardBday, np.sum(cts&gt;1))#keep this !!\n  #shardBday = np.sum(cts&gt;1)\n\n\n#np.sum(shardBday&gt;0)/1000\nnp.mean(shardBday &gt; 0)\n\n#shardBday = 2\n\n0.893\n\n\n\n5 != 3 #not equal\n\nTrue\n\n\n\n#Boolean indexing !!\nx[cts &gt; 1]\n\narray([ 71, 192])\n\n\n\nx[23]\n\n182\n\n\n\n#can you design a coin flip with an arbitary probability p = 0.25\n#simulate 365 days with a 1/4 chance of being sunny\n\n#fair coin\ncoins = np.random.randint(0,2,365)\n\nnp.unique(coins, return_counts=True)\n\n(array([0, 1]), array([189, 176], dtype=int64))\n\n\n\n\nTossing dice and coins\nLet us toss many dice or coins to find out: - the average value of a six-faced die - the variation around the mean when averaging - the probability of various “common hands” in the game Liar’s Dice: * Full house: e.g., 66111 * Three of a kind: e.g., 44432 * Two pair: e.g., 22551 * Pair: e.g., 66532\nSome real world problems: 1. Overbooking flights: airlines 2. Home Office days: planning office capacities and minimizing social isolation"
  },
  {
    "objectID": "Lecture4.html#introduction-to-pandas",
    "href": "Lecture4.html#introduction-to-pandas",
    "title": "Lecture 4",
    "section": "Introduction to pandas",
    "text": "Introduction to pandas\nWhile numpy offers a lot of powerful numerical capabilities it lacks some of the necessary convenience and natural of handling data as we encounter them. For example, we would typically like to - mix data types (strings, numbers, categories, Boolean, …) - refer to columns and rows by names - summarize and visualize data in efficient pivot style manners\nAll of the above (and more) can be achieved easily by extending the concept of an array (or a matrix) to a so called dataframe.\nThere are many ways to construct a DataFrame, though one of the most common is from a dictionary of equal-length lists or NumPy arrays:\n\ndata = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n        \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n        \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\nframe = pd.DataFrame(data)# creates a dataframe out of the data given!\nframe.head(3)\n\n\n  \n    \n      \n\n\n\n\n\n\nstate\nyear\npop\n\n\n\n\n0\nOhio\n2000\n1.5\n\n\n1\nOhio\n2001\n1.7\n\n\n2\nOhio\n2002\n3.6\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nframe[2,1]#too bad\n\n\n#to get the full row: use the .iloc method\nframe.iloc[2]\nframe.iloc[2,1]\n\n2002\n\n\n\nSubsetting/Slicing\nWe first need to understand the attributes index (=rownames) and columns (= column names):\n\nframe.index\n\nRangeIndex(start=0, stop=6, step=1)\n\n\n\n#We can set a column as an index:\nframe2 = frame.set_index(\"year\")\nprint(frame2)\n# \n\n       state  pop\nyear             \n2000    Ohio  1.5\n2001    Ohio  1.7\n2002    Ohio  3.6\n2001  Nevada  2.4\n2002  Nevada  2.9\n2003  Nevada  3.2\n\n\n\n#it would be nice to access elements in the same fashion as numpy\n#frame2[1,1]\nframe[\"pop\"]\n\n0    1.5\n1    1.7\n2    3.6\n3    2.4\n4    2.9\n5    3.2\nName: pop, dtype: float64\n\n\n\nframe.pop\n\n&lt;bound method DataFrame.pop of     state  year  pop\n0    Ohio  2000  1.5\n1    Ohio  2001  1.7\n2    Ohio  2002  3.6\n3  Nevada  2001  2.4\n4  Nevada  2002  2.9\n5  Nevada  2003  3.2&gt;\n\n\n\n\nAsking for rows\nUnfortunately, we cannot use the simple [row,col] notation that we are used to from numpy arrays. (Try asking for frame[0,1])\nInstead, row subsetting can be achieved with either the .loc() or the .iloc() methods. The latter takes integers, the former indices:\n\nframe2.loc[2001] #note that I am not using quotes !!\n#at first glance this looks like I am asking for the row number 2001 !!\n\n\n  \n    \n      \n\n\n\n\n\n\nstate\npop\n\n\nyear\n\n\n\n\n\n\n2001\nOhio\n1.7\n\n\n2001\nNevada\n2.4\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nframe2.loc[2001,\"state\"]\n\nyear\n2001      Ohio\n2001    Nevada\nName: state, dtype: object\n\n\n\nframe.iloc[0]#first row\n\nstate    Ohio\nyear     2000\npop       1.5\nName: 0, dtype: object\n\n\n\nframe3 = frame.set_index(\"state\", drop=False)\nprint(frame3)\n\n         state  year  pop\nstate                    \nOhio      Ohio  2000  1.5\nOhio      Ohio  2001  1.7\nOhio      Ohio  2002  3.6\nNevada  Nevada  2001  2.4\nNevada  Nevada  2002  2.9\nNevada  Nevada  2003  3.2\n\n\n\nframe3.loc[\"Ohio\"]\n\n\n  \n    \n      \n\n\n\n\n\n\nyear\npop\n\n\nstate\n\n\n\n\n\n\nOhio\n2000\n1.5\n\n\nOhio\n2001\n1.7\n\n\nOhio\n2002\n3.6\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nframe.iloc[2001]# this does not work because we do not have 2001 rows !\n\n\nframe.iloc[0,1]\n\n2000\n\n\n\n\nAsking for columns\n\n#The columns are also an index:\nframe.columns\n\nIndex(['state', 'year', 'pop'], dtype='object')\n\n\nA column in a DataFrame can be retrieved MUCH easier: as a Series either by dictionary-like notation or by using the dot attribute notation:\n\nframe[\"state\"]\n\n0      Ohio\n1      Ohio\n2      Ohio\n3    Nevada\n4    Nevada\n5    Nevada\nName: state, dtype: object\n\n\n\nframe.year#equivalent to frame[\"year\"]\n\n0    2000\n1    2001\n2    2002\n3    2001\n4    2002\n5    2003\nName: year, dtype: int64\n\n\n\n\nSummary Stats\nJust like in numpy you can compute sums, means, counts and many other summaries along rows and columns, by specifying the axis argument:\n\nheight = np.array([1.79, 1.85, 1.95, 1.55])\nweight = np.array([70, 80, 85, 65])\nhw = np.array([height, weight]).transpose()\n\nhw\n\narray([[ 1.79, 70.  ],\n       [ 1.85, 80.  ],\n       [ 1.95, 85.  ],\n       [ 1.55, 65.  ]])\n\n\n\ndf = pd.DataFrame(hw, columns = [\"height\", \"weight\"]) \nprint(df)\n\n   height  weight\n0    1.79    70.0\n1    1.85    80.0\n2    1.95    85.0\n3    1.55    65.0\n\n\n\ndf = pd.DataFrame(hw , columns = [\"height\", \"weight\"],\n                  index = [\"Peter\", \"Matilda\", \"Bee\", \"Tom\"]) \nprint(df)\n\n         height  weight\nPeter      1.79    70.0\nMatilda    1.85    80.0\nBee        1.95    85.0\nTom        1.55    65.0\n\n\nCan you extract:\n\nAll weights\nPeter’s height\nBee’s full info\nthe average height\nget all persons with height greater than 180cm\n\n\n#see Lab5\n\n\nprint(df.mean(axis=0))\nprint(df.mean(axis=1))# are these averages sensible ?\n\nheight     1.785\nweight    75.000\ndtype: float64\nPeter      35.895\nMatilda    40.925\nBee        43.475\nBee        33.275\ndtype: float64\n\n\nSome methods are neither reductions nor accumulations. describe is one such example, producing multiple summary statistics in one shot:\n\ndf.describe()\n\n\n\n\n\n\n\n\nheight\nweight\n\n\n\n\ncount\n4.000\n4.000000\n\n\nmean\n1.785\n75.000000\n\n\nstd\n0.170\n9.128709\n\n\nmin\n1.550\n65.000000\n\n\n25%\n1.730\n68.750000\n\n\n50%\n1.820\n75.000000\n\n\n75%\n1.875\n81.250000\n\n\nmax\n1.950\n85.000000"
  },
  {
    "objectID": "Lecture4.html#built-in-data-sets",
    "href": "Lecture4.html#built-in-data-sets",
    "title": "Lecture 4",
    "section": "Built in data sets",
    "text": "Built in data sets"
  },
  {
    "objectID": "Lecture4.html#gapminder-data",
    "href": "Lecture4.html#gapminder-data",
    "title": "Lecture 4",
    "section": "Gapminder Data",
    "text": "Gapminder Data\nhttps://www.gapminder.org/fw/world-health-chart/\nhttps://www.ted.com/talks/hans_rosling_the_best_stats_you_ve_ever_seen#t-241405\n\nYou’ve never seen data presented like this. With the drama and urgency of a sportscaster, statistics guru Hans Rosling debunks myths about the so-called “developing world.”\n\n\n!pip install gapminder\n#!conda install gapminder\nfrom gapminder import gapminder\n#gapminder.to_csv(\"../datasets/gapminder.csv\")\n\n\ngapminder\n\n\n  \n    \n      \n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1699\nZimbabwe\nAfrica\n1987\n62.351\n9216418\n706.157306\n\n\n1700\nZimbabwe\nAfrica\n1992\n60.377\n10704340\n693.420786\n\n\n1701\nZimbabwe\nAfrica\n1997\n46.809\n11404948\n792.449960\n\n\n1702\nZimbabwe\nAfrica\n2002\n39.989\n11926563\n672.038623\n\n\n1703\nZimbabwe\nAfrica\n2007\n43.487\n12311143\n469.709298\n\n\n\n\n\n1704 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#find the unique years\n\n#get the years:\ngapminder[\"year\"]\nnp.unique(gapminder.year)\n\narray([1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002,\n       2007])\n\n\n\n#get all rows with year 1952:\n#Hint:\n#either use Boolean subsetting\ngapminder[\"year\"] == 1952\ngapminder[gapminder[\"year\"] == 1952]\n#or use an index !!\n\n\n  \n    \n      \n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n\n\n12\nAlbania\nEurope\n1952\n55.230\n1282697\n1601.056136\n\n\n24\nAlgeria\nAfrica\n1952\n43.077\n9279525\n2449.008185\n\n\n36\nAngola\nAfrica\n1952\n30.015\n4232095\n3520.610273\n\n\n48\nArgentina\nAmericas\n1952\n62.485\n17876956\n5911.315053\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1644\nVietnam\nAsia\n1952\n40.412\n26246839\n605.066492\n\n\n1656\nWest Bank and Gaza\nAsia\n1952\n43.160\n1030585\n1515.592329\n\n\n1668\nYemen, Rep.\nAsia\n1952\n32.548\n4963829\n781.717576\n\n\n1680\nZambia\nAfrica\n1952\n42.038\n2672000\n1147.388831\n\n\n1692\nZimbabwe\nAfrica\n1952\n48.451\n3080907\n406.884115\n\n\n\n\n\n142 rows × 6 columns"
  },
  {
    "objectID": "Lecture4.html#handling-files",
    "href": "Lecture4.html#handling-files",
    "title": "Lecture 4",
    "section": "Handling Files",
    "text": "Handling Files\nGet to know your friends\n\npd.read_csv\npd.read_table\npd.read_excel\n\n\n'''url = \"https://drive.google.com/file/d/1oIvCdN15UEwt4dCyjkArekHnTrivN43v/view?usp=share_link\"\nurl='https://drive.google.com/uc?id=' + url.split('/')[-2]\ngapminder = pd.read_csv(url, index_col=0)\ngapminder.head()'''\n\n\n  \n    \n      \n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ngapminder.sort_values(by=\"year\").head()\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n\n\n528\nFrance\nEurope\n1952\n67.410\n42459667\n7029.809327\n\n\n540\nGabon\nAfrica\n1952\n37.003\n420702\n4293.476475\n\n\n1656\nWest Bank and Gaza\nAsia\n1952\n43.160\n1030585\n1515.592329\n\n\n552\nGambia\nAfrica\n1952\n30.000\n284320\n485.230659\n\n\n\n\n\n\n\n\n#How many countries?\nCtryCts = gapminder[\"country\"].value_counts()\nCtryCts\n#note the similarity with np.unique(..., return_counts=True)\n\nAfghanistan          12\nPakistan             12\nNew Zealand          12\nNicaragua            12\nNiger                12\n                     ..\nEritrea              12\nEquatorial Guinea    12\nEl Salvador          12\nEgypt                12\nZimbabwe             12\nName: country, Length: 142, dtype: int64\n\n\n\nfrom numpy.random import default_rng\nrng = default_rng()\nrng.choice(gapminder[\"country\"].unique(),2)\ngapminder[\"year\"].unique()\n\narray([1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002,\n       2007])\n\n\n\n#How meaningful are the column stats?\nprint(gapminder.mean(axis=0))\ngapminder.describe()\n\nyear         1.979500e+03\nlifeExp      5.947444e+01\npop          2.960121e+07\ngdpPercap    7.215327e+03\ndtype: float64\n\n\n/var/folders/h4/k73g68ds6xj791sf8cpmlxlc0000gn/T/ipykernel_33611/633466148.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  print(gapminder.mean(axis=0))\n\n\n\n\n\n\n\n\n\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\ncount\n1704.00000\n1704.000000\n1.704000e+03\n1704.000000\n\n\nmean\n1979.50000\n59.474439\n2.960121e+07\n7215.327081\n\n\nstd\n17.26533\n12.917107\n1.061579e+08\n9857.454543\n\n\nmin\n1952.00000\n23.599000\n6.001100e+04\n241.165876\n\n\n25%\n1965.75000\n48.198000\n2.793664e+06\n1202.060309\n\n\n50%\n1979.50000\n60.712500\n7.023596e+06\n3531.846988\n\n\n75%\n1993.25000\n70.845500\n1.958522e+07\n9325.462346\n\n\nmax\n2007.00000\n82.603000\n1.318683e+09\n113523.132900\n\n\n\n\n\n\n\nSort the index before you slice!!\nChoose a time range and specific countries\n\ngapminder2 = gapminder.set_index(\"year\").sort_index()\ngap1982_92 = gapminder2.loc[1982:1992].reset_index()\ngap1982_92 = gap1982_92.set_index(\"country\").sort_index()\ngap1982_92.loc[\"Afghanistan\":\"Albania\"]\n\n\n\n\n\n\n\n\nyear\ncontinent\nlifeExp\npop\ngdpPercap\n\n\ncountry\n\n\n\n\n\n\n\n\n\nAfghanistan\n1982\nAsia\n39.854\n12881816\n978.011439\n\n\nAfghanistan\n1987\nAsia\n40.822\n13867957\n852.395945\n\n\nAfghanistan\n1992\nAsia\n41.674\n16317921\n649.341395\n\n\nAlbania\n1992\nEurope\n71.581\n3326498\n2497.437901\n\n\nAlbania\n1987\nEurope\n72.000\n3075321\n3738.932735\n\n\nAlbania\n1982\nEurope\n70.420\n2780097\n3630.880722\n\n\n\n\n\n\n\n\ngap1982_92.loc[\"Afghanistan\":\"Albania\",\"lifeExp\"].mean()\n\n56.0585"
  },
  {
    "objectID": "Lecture5.html#data-manipulation-with-pandas",
    "href": "Lecture5.html#data-manipulation-with-pandas",
    "title": "Lecture 5",
    "section": "Data Manipulation with pandas",
    "text": "Data Manipulation with pandas\nWhile we have seen panda’s ability to (i) mix data types (strings, numbers, categories, Boolean, …) and (ii) refer to columns and rows by names, this library offers a lot more powerful tools for efficiently gaining insights from data, e.g.\n\nsummarize/aggregate data in efficient pivot style manners\nhandling missing values\nvisualize/plot data\n\n\n!pip install gapminder\nfrom gapminder import gapminder"
  },
  {
    "objectID": "Lecture5.html#handling-files",
    "href": "Lecture5.html#handling-files",
    "title": "Lecture 5",
    "section": "Handling Files",
    "text": "Handling Files\nGet to know your friends\n\npd.read_csv\npd.read_table\npd.read_excel\n\nBut before that we need to connect to our Google drives ! (more instructions can be found here)\n\n\"Sam\" + \" Altman\" \n\n'Sam Altman'\n\n\nCounting and Summary Statistics\n\ngapminder.sort_values(by=\"year\").head()\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n\n\n528\nFrance\nEurope\n1952\n67.410\n42459667\n7029.809327\n\n\n540\nGabon\nAfrica\n1952\n37.003\n420702\n4293.476475\n\n\n1656\nWest Bank and Gaza\nAsia\n1952\n43.160\n1030585\n1515.592329\n\n\n552\nGambia\nAfrica\n1952\n30.000\n284320\n485.230659\n\n\n\n\n\n\n\n\n#How many countries?\nCtryCts = gapminder[\"country\"].value_counts()\nCtryCts\n#note the similarity with np.unique(..., return_counts=True)\n\nAfghanistan          12\nPakistan             12\nNew Zealand          12\nNicaragua            12\nNiger                12\n                     ..\nEritrea              12\nEquatorial Guinea    12\nEl Salvador          12\nEgypt                12\nZimbabwe             12\nName: country, Length: 142, dtype: int64"
  },
  {
    "objectID": "Lecture5.html#grouped-operations",
    "href": "Lecture5.html#grouped-operations",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nThe gapminder data is a good example for wanting to apply functions to subsets to data that correspond to categories, e.g. * by year * by country * by continent\nThe powerful pandas .groupby() method enables exactly this goal rather elegantly and efficiently.\nFirst, think how you could possibly compute the average GDP seprataley for each continent. The numpy.mean(..., axis=...) will not help you.\nInstead you will have to manually find all continents and then use Boolean logic:\n\ncontinents =np.unique(gapminder[\"continent\"])\ncontinents\n\narray(['Africa', 'Americas', 'Asia', 'Europe', 'Oceania'], dtype=object)\n\n\n\nAfricaRows = gapminder[\"continent\"]==\"Africa\"\ngapminder[AfricaRows][\"gdpPercap\"].mean()\n\n\n#you could use a for loop instead, of course\ngapminder[gapminder[\"continent\"]==\"Africa\"][\"gdpPercap\"].mean()\ngapminder[gapminder[\"continent\"]==\"Americas\"][\"gdpPercap\"].mean()\ngapminder[gapminder[\"continent\"]==\"Asia\"][\"gdpPercap\"].mean()\ngapminder[gapminder[\"continent\"]==\"Europe\"][\"gdpPercap\"].mean()\ngapminder[gapminder[\"continent\"]==\"Oceania\"][\"gdpPercap\"].mean()\n\n18621.609223333333\n\n\nInstead, we should embrace the concept of grouping by a variable\n\ngapminder.mean()\n\nFutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  gapminder.mean()\n\n\nyear         1.979500e+03\nlifeExp      5.947444e+01\npop          2.960121e+07\ngdpPercap    7.215327e+03\ndtype: float64\n\n\n\nbyContinent = gapminder.groupby(\"continent\")\nbyContinent.mean()\n\nFutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  byContinent.mean()\n\n\n\n  \n    \n      \n\n\n\n\n\n\nyear\nlifeExp\npop\ngdpPercap\n\n\ncontinent\n\n\n\n\n\n\n\n\nAfrica\n1979.5\n48.865330\n9.916003e+06\n2193.754578\n\n\nAmericas\n1979.5\n64.658737\n2.450479e+07\n7136.110356\n\n\nAsia\n1979.5\n60.064903\n7.703872e+07\n7902.150428\n\n\nEurope\n1979.5\n71.903686\n1.716976e+07\n14469.475533\n\n\nOceania\n1979.5\n74.326208\n8.874672e+06\n18621.609223\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#only lifeExp:\nbyContinent[\"lifeExp\"].max()\n#maybe there is more to life than the mean\n\n76.442\n\n\n\nbyContinent[\"gdpPercap\"].agg([min,max, np.mean])\n\n\n  \n    \n      \n\n\n\n\n\n\nmin\nmax\nmean\n\n\ncontinent\n\n\n\n\n\n\n\nAfrica\n241.165876\n21951.21176\n2193.754578\n\n\nAmericas\n1201.637154\n42951.65309\n7136.110356\n\n\nAsia\n331.000000\n113523.13290\n7902.150428\n\n\nEurope\n973.533195\n49357.19017\n14469.475533\n\n\nOceania\n10039.595640\n34435.36744\n18621.609223\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#multiple aggregating functions (no built in function mean)\ngapminder.groupby(\"continent\")[\"gdpPercap\"].agg([min,max, np.mean])\n\n\n  \n    \n      \n\n\n\n\n\n\nmin\nmax\nmean\n\n\ncontinent\n\n\n\n\n\n\n\nAfrica\n241.165876\n21951.21176\n2193.754578\n\n\nAmericas\n1201.637154\n42951.65309\n7136.110356\n\n\nAsia\n331.000000\n113523.13290\n7902.150428\n\n\nEurope\n973.533195\n49357.19017\n14469.475533\n\n\nOceania\n10039.595640\n34435.36744\n18621.609223\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nbyContinentYear = gapminder.groupby([\"continent\", \"year\"])[\"gdpPercap\"]\nbyContinentYear.mean()\n\n\n#multiple keys\ngapminder[\"past1990\"] = gapminder[\"year\"] &gt; 1990\nbyContinentYear = gapminder.groupby([\"continent\", \"past1990\"])[\"gdpPercap\"]\nbyContinentYear.mean()\n\ncontinent  past1990\nAfrica     False        1997.008411\n           True         2587.246913\nAmericas   False        6051.047533\n           True         9306.236000\nAsia       False        6713.113041\n           True        10280.225202\nEurope     False       11341.142807\n           True        20726.140986\nOceania    False       15224.015414\n           True        25416.796842\nName: gdpPercap, dtype: float64\n\n\n\n\nTitanic data\n\n# Since pandas does not have any built in data, I am going to \"cheat\" and \n# make use of the `seaborn` library\nimport seaborn as sns \n\ntitanic = sns. load_dataset('titanic')\ntitanic[\"3rdClass\"] = titanic[\"pclass\"]==3\ntitanic[\"male\"] = titanic[\"sex\"]==\"male\"\n\ntitanic\n\n\n  \n    \n      \n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n3rdClass\nmale\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\nTrue\nTrue\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\nFalse\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\nTrue\nFalse\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\nFalse\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\nTrue\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0\n2\nmale\n27.0\n0\n0\n13.0000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nno\nTrue\nFalse\nTrue\n\n\n887\n1\n1\nfemale\n19.0\n0\n0\n30.0000\nS\nFirst\nwoman\nFalse\nB\nSouthampton\nyes\nTrue\nFalse\nFalse\n\n\n888\n0\n3\nfemale\nNaN\n1\n2\n23.4500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nno\nFalse\nTrue\nFalse\n\n\n889\n1\n1\nmale\n26.0\n0\n0\n30.0000\nC\nFirst\nman\nTrue\nC\nCherbourg\nyes\nTrue\nFalse\nTrue\n\n\n890\n0\n3\nmale\n32.0\n0\n0\n7.7500\nQ\nThird\nman\nTrue\nNaN\nQueenstown\nno\nTrue\nTrue\nTrue\n\n\n\n\n\n891 rows × 17 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#overall survival rate\ntitanic.survived.mean()\n\n0.3838383838383838\n\n\nTasks:\n\ncompute the proportion of survived separately for\n\nmale/female\nthe three classes\nPclass and sex\n\ncompute the mean age separately for male/female\n\n\n#I would like to compute the mean survical seprately for each group\nbySex = titanic.groupby(\"sex\")\n#here I am specifically asking for the mean\nbySex[\"survived\"].mean()\n#if you want multiple summaries, you can list them all inside the agg():\nbySex[\"survived\"].agg([min, max, np.mean ])\n\n\n  \n    \n      \n\n\n\n\n\n\nmin\nmax\nmean\n\n\nsex\n\n\n\n\n\n\n\nfemale\n0\n1\n0.742038\n\n\nmale\n0\n1\n0.188908\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#I would like to compute the mean survical seprately for each group\nbySexPclass = titanic.groupby([\"pclass\", \"sex\"])\n#here I am specifically asking for the mean\nbySexPclass[\"survived\"].mean()\n\npclass  sex   \n1       female    0.968085\n        male      0.368852\n2       female    0.921053\n        male      0.157407\n3       female    0.500000\n        male      0.135447\nName: survived, dtype: float64\n\n\n\nbySex = titanic.groupby(\"sex\")\n#here I am specifically asking for the mean\nbySex[\"survived\"].mean()"
  },
  {
    "objectID": "Lecture5.html#plotting",
    "href": "Lecture5.html#plotting",
    "title": "Lecture 5",
    "section": "Plotting",
    "text": "Plotting\nWe will not spend much time with basic plots in matplotlib but instead move quickly toward the pandas versions of these functions.\n\n#%matplotlib inline\nimport matplotlib.pyplot as plt\n\n#plt.rcParams['figure.dpi'] = 800\nyear = [1950, 1970, 1990, 2010]\npop = [2.519, 3.692, 5.263, 6.972]\nplt.plot(year, pop)\n#plt.bar(year, pop)\n#plt.scatter(year, pop)\nplt.xlabel('Year')\nplt.ylabel('Population')\nplt.title('World Population')\nx = 1\n#plt.show()\n\n\n\n\npandas offers plots directly from its objects\n\ntitanic.age.hist()\nplt.show()\n\n\n\n\nAnd often the axis labels are taken care of\n\n#titanic.groupby(\"pclass\").survived.mean().plot.bar()\nSurvByPclass = titanic.groupby(\"pclass\").survived.mean()\n\nSurvByPclass.plot(kind=\"bar\", title = \"Mean Survival\")\n\n&lt;Axes: title={'center': 'Mean Survival'}, xlabel='pclass'&gt;\n\n\n\n\n\nBut you can customize each plot as you wish:\n\nSurvByPclass.plot(kind=\"bar\", x = \"Passenger Class\", y = \"Survived\", title = \"Mean Survival\")\n\n&lt;Axes: title={'center': 'Mean Survival'}, xlabel='pclass'&gt;\n\n\n\n\n\nTasks:\n\nCompute the avg. life expectancy in the gapminder data for each year\nPlot this as a line plot and give meaningful x and y labels and a title\n\n\nlifeExpbyYear = gapminder.groupby(\"year\")[\"lifeExp\"].mean()\n\nlifeExpbyYear.plot(y= \"avg. life Exp\", title = \"Average life Expectancvy per year\")\n\n&lt;Axes: title={'center': 'Average life Expectancvy per year'}, xlabel='year'&gt;"
  },
  {
    "objectID": "Lecture5.html#advanced-topics",
    "href": "Lecture5.html#advanced-topics",
    "title": "Lecture 5",
    "section": "Advanced topics",
    "text": "Advanced topics\n\nCreating Dataframes\n\nZip\nFrom list of dicts\n\n\n\nIndexing:\n\nmultilevel indexes\nsorting\nasking for ranges"
  },
  {
    "objectID": "Lecture5.html#types-of-columns",
    "href": "Lecture5.html#types-of-columns",
    "title": "Lecture 5",
    "section": "Types of columns",
    "text": "Types of columns\n\ncategorical\ndates\n\n\n# Creating Dataframes\n#using zip\n# List1\nName = ['tom', 'krish', 'nick', 'juli']\n  \n# List2\nAge = [25, 30, 26, 22]\n  \n# get the list of tuples from two lists.\n# and merge them by using zip().\nlist_of_tuples = list(zip(Name, Age))\nlist_of_tuples = zip(Name, Age)\n# Assign data to tuples.\n#print(list_of_tuples)\n  \n  \n# Converting lists of tuples into\n# pandas Dataframe.\ndf = pd.DataFrame(list_of_tuples,\n                  columns=['Name', 'Age'])\n  \n# Print data.\ndf\n\n\n\n\n\n\n\n\nName\nAge\n\n\n\n\n0\ntom\n25\n\n\n1\nkrish\n30\n\n\n2\nnick\n26\n\n\n3\njuli\n22\n\n\n\n\n\n\n\n\n#from list of dicts\ndata = [{'a': 1, 'b': 2, 'c': 3},\n        {'a': 10, 'b': 20, 'c': 30}]\n  \n# Creates DataFrame.\ndf = pd.DataFrame(data)\n  \ndf\n\n\n\n\n\n\n\n\na\nb\nc\n\n\n\n\n0\n1\n2\n3\n\n\n1\n10\n20\n30\n\n\n\n\n\n\n\n\n# Indexing:\n\nadvLesson = True\nif advLesson:\n    frame2 = frame.set_index([\"year\", \"state\"])\n    print(frame2)\n    frame3 = frame2.sort_index()\n    print(frame3)\n    print(frame.loc[:,\"state\":\"year\"])\n\n             pop\nyear state      \n2000 Ohio    1.5\n2001 Ohio    1.7\n2002 Ohio    3.6\n2001 Nevada  2.4\n2002 Nevada  2.9\n2003 Nevada  3.2\n             pop\nyear state      \n2000 Ohio    1.5\n2001 Nevada  2.4\n     Ohio    1.7\n2002 Nevada  2.9\n     Ohio    3.6\n2003 Nevada  3.2\n    state  year\n0    Ohio  2000\n1    Ohio  2001\n2    Ohio  2002\n3  Nevada  2001\n4  Nevada  2002\n5  Nevada  2003\n\n\n\nInplace\nNote that I reassigned the objects in the code above. That is because most operations, such as set_index, sort_index, drop, etc. do not operate inplace unless specified!"
  },
  {
    "objectID": "Lecture6.html#plotting",
    "href": "Lecture6.html#plotting",
    "title": "Lecture 6",
    "section": "Plotting",
    "text": "Plotting\nThe “plot type of the day” is one of the most popular ones used to display data distributions, the boxplot.\nBoxplots, also known as box-and-whisker plots, are a statistical visualization tool that provides a concise summary of a dataset’s distribution. They display key descriptive statistics and provide insights into the central tendency, variability, and skewness of the data. Here’s a brief introduction and motivation for using boxplots:\n\nStructure of Boxplots: Boxplots consist of a box and whiskers that represent different statistical measures of the data:\n\nThe box represents the interquartile range (IQR), which spans from the lower quartile (25th percentile) to the upper quartile (75th percentile). The width of the box indicates the spread of the middle 50% of the data.\nA line (whisker) extends from each end of the box to show the minimum and maximum values within a certain range (often defined as 1.5 times the IQR).\nPoints beyond the whiskers are considered outliers and plotted individually.\n\nMotivation for Using Boxplots: Boxplots offer several benefits and are commonly used for the following reasons:\n\nVisualizing Data Distribution: Boxplots provide a concise overview of the distribution of a dataset. They show the skewness, symmetry, and presence of outliers, allowing for quick identification of key features.\nComparing Groups: Boxplots enable easy visual comparison of multiple groups or categories. By placing side-by-side boxplots, you can assess differences in central tendency and variability between groups.\nOutlier Detection: Boxplots explicitly mark outliers, aiding in the identification of extreme values or data points that deviate significantly from the overall pattern.\nData Summary: Boxplots summarize key statistics, including the median, quartiles, and range, providing a quick understanding of the dataset without the need for detailed calculations.\nRobustness: Boxplots are relatively robust to skewed or asymmetric data and can effectively handle datasets with outliers.\n\n\nBoxplots are widely used in various fields, including data analysis, exploratory data visualization, and statistical reporting. They offer a clear and concise representation of data distribution, making them a valuable tool for understanding and communicating the characteristics of a dataset.\n\n!pip install gapminder\nfrom gapminder import gapminder\n\n\ngapminder\n\n\n  \n    \n      \n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1699\nZimbabwe\nAfrica\n1987\n62.351\n9216418\n706.157306\n\n\n1700\nZimbabwe\nAfrica\n1992\n60.377\n10704340\n693.420786\n\n\n1701\nZimbabwe\nAfrica\n1997\n46.809\n11404948\n792.449960\n\n\n1702\nZimbabwe\nAfrica\n2002\n39.989\n11926563\n672.038623\n\n\n1703\nZimbabwe\nAfrica\n2007\n43.487\n12311143\n469.709298\n\n\n\n\n\n1704 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\nThe pandas way\n\ngapminder.boxplot(column = \"lifeExp\", by=\"continent\");\n\n\n\n\nThe matplotlib way\n\nplt.boxplot(gapminder[\"continent\"], gapminder[\"lifeExp\"]);\n\n\nTask\n\nCreate a boxplot for gdpPercap instead. What do you notice ? Are you happy with how the plot looks? Any “trick” you can think to make this more readable?\nAdvanced: can you create boxplots for gdpPerCap and lifeExp in one command?\n\n\ngapminder.boxplot(column = \"gdpPercap\", by=\"continent\");\nplt.yscale(\"log\")\n\n\n\n\n\nFurther Reading:\n\nPython Plotting With Matplotlib Tutorial.)\n\n\nimport numpy as np\nfrom scipy.stats import entropy\n\np = np.array([1/100, 99/100])\nn=2\n#p = np.array(np.ones)/n\nH = entropy(p, base=2)\nH\n\n0.08079313589591118"
  },
  {
    "objectID": "Lecture7.html#categorical-variables",
    "href": "Lecture7.html#categorical-variables",
    "title": "Lecture 7",
    "section": "Categorical variables",
    "text": "Categorical variables\nAs a motivation, take another look at the gapminder data which contains variables of a mixed type: numeric columns along with string type columns which contain repeated instances of a smaller set of distinct or discrete values which\n\nare not numeric (but could be represented as numbers)\ncannot really be ordered\ntypically take on a finite set of values, or categories.\n\nWe refer to these data types as categorical.\nWe have already seen functions like unique and value_counts, which enable us to extract the distinct values from an array and compute their frequencies.\nBoxplots and grouping operations typically use a categorical variable to compute summaries of a numerical variables for each category separately, e.g.\n\ngapminder.boxplot(column = \"lifeExp\", by=\"continent\",figsize=(5, 2));\nplt.title('Life expectancy by continent')\n# Remove the default suptitle\nplt.suptitle(\"\");\n\n\n\n\npandas has a special Categorical extension type for holding data that uses the integer-based categorical representation or encoding. This is a popular data compression technique for data with many occurrences of similar values and can provide significantly faster performance with lower memory use, especially for string data.\n\ngapminder.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1704 entries, 0 to 1703\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   country    1704 non-null   object \n 1   continent  1704 non-null   object \n 2   year       1704 non-null   int64  \n 3   lifeExp    1704 non-null   float64\n 4   pop        1704 non-null   int64  \n 5   gdpPercap  1704 non-null   float64\ndtypes: float64(2), int64(2), object(2)\nmemory usage: 80.0+ KB\n\n\n\ngapminder['country'] = gapminder['country'].astype('category')\ngapminder.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1704 entries, 0 to 1703\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype   \n---  ------     --------------  -----   \n 0   country    1704 non-null   category\n 1   continent  1704 non-null   object  \n 2   year       1704 non-null   int64   \n 3   lifeExp    1704 non-null   float64 \n 4   pop        1704 non-null   int64   \n 5   gdpPercap  1704 non-null   float64 \ndtypes: category(1), float64(2), int64(2), object(1)\nmemory usage: 75.2+ KB\n\n\nWe will come back to the usefulness of this later."
  },
  {
    "objectID": "Lecture7.html#tables-as-models",
    "href": "Lecture7.html#tables-as-models",
    "title": "Lecture 7",
    "section": "Tables as models",
    "text": "Tables as models\nFor now let us look at our first “model”:\n\ntitanic.head()\n\n\n  \n    \n      \n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n3rdClass\nmale\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\nTrue\nTrue\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\nFalse\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\nTrue\nFalse\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\nFalse\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\nTrue\nTrue\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ntitanic = sns.load_dataset('titanic')\ntitanic[\"3rdClass\"] = (titanic[\"pclass\"]==3)\ntitanic[\"male\"] = (titanic[\"sex\"]==\"male\")\nvals1, cts1 = np.unique(titanic[\"3rdClass\"], return_counts=True)\nprint(cts1)\nprint(vals1)\n\n[400 491]\n[False  True]\n\n\n\nprint(\"The mean survival on the Titanic was\", np.mean(titanic.survived))\n\nThe mean survival on the Titanic was 0.3838383838383838\n\n\n\nConTbl = pd.crosstab(titanic[\"sex\"], titanic[\"survived\"])\nConTbl\n\n\n  \n    \n      \n\n\n\n\n\nsurvived\n0\n1\n\n\nsex\n\n\n\n\n\n\nfemale\n81\n233\n\n\nmale\n468\n109\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\nWhat are the estimated survival probabilities?\n\n#the good old groupby way:\nbySex = titanic.groupby(\"sex\").survived\nbySex.mean()\n\nsex\nfemale    0.742038\nmale      0.188908\nName: survived, dtype: float64\n\n\n\np3D = pd.crosstab([titanic[\"sex\"], titanic[\"3rdClass\"]], titanic[\"survived\"])\np3D\n\n\n  \n    \n      \n\n\n\n\n\n\nsurvived\n0\n1\n\n\nsex\n3rdClass\n\n\n\n\n\n\nfemale\nFalse\n9\n161\n\n\nTrue\n72\n72\n\n\nmale\nFalse\n168\n62\n\n\nTrue\n300\n47\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\nWhat are the estimated survival probabilities?\n\n#the good old groupby way:\nbySex = titanic.groupby([\"sex\", \"3rdClass\"]).survived\nbySex.mean()\n\nsex     3rdClass\nfemale  False       0.947059\n        True        0.500000\nmale    False       0.269565\n        True        0.135447\nName: survived, dtype: float64\n\n\nThe above table can be looked at as a model, which is defined as a function which takes inputs x and “spits out” a prediction:\n\\(y = f(\\mathbf{x})\\)\nIn our case, the inputs are \\(x_1=\\text{sex}\\), \\(x_2=\\text{3rdClass}\\), and the output is the estimated survival probability!\nIt is evident that we could keep adding more input variables and make finer and finer grained predictions.\n\nModeling Missing Values\nWe have already seen how to detect and how to replace missing values. But the latter -until now- was rather crude: we often replaced all values with a “global” average.\nClearly, we can do better than replacing all missing entries in the survived column with the average \\(0.38\\).\n\nrng = default_rng()\n\nmissingRows = rng.integers(0,890,20)\nprint(missingRows)\n#introduce missing values\ntitanic.iloc[missingRows,0] = np.nan\n\n[409 881 389 717 378 547 134 351 691 134 212  99  69 642 700 861 205   8\n 559 864]\n\n\n\nnp.sum(titanic.survived.isna())\n\n36\n\n\n\nFrom categorical to numerical relations\n\nurl = \"https://drive.google.com/file/d/1UbZy5Ecknpl1GXZBkbhJ_K6GJcIA2Plq/view?usp=share_link\" \nurl='https://drive.google.com/uc?id=' + url.split('/')[-2]\nauto = pd.read_csv(url)\nauto.head()\n\n\n  \n    \n      \n\n\n\n\n\n\nmpg\ncylinders\ndisplacement\nhorsepower\nweight\nacceleration\nyear\norigin\nname\nManufacturer\n\n\n\n\n0\n18.0\n8\n307.0\n130\n3504\n12.0\n70\n1\nchevrolet chevelle malibu\nchevrolet\n\n\n1\n15.0\n8\n350.0\n165\n3693\n11.5\n70\n1\nbuick skylark 320\nbuick\n\n\n2\n18.0\n8\n318.0\n150\n3436\n11.0\n70\n1\nplymouth satellite\nplymouth\n\n\n3\n16.0\n8\n304.0\n150\n3433\n12.0\n70\n1\namc rebel sst\namc\n\n\n4\n17.0\n8\n302.0\n140\n3449\n10.5\n70\n1\nford torino\nford\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nplt.figure(figsize=(5,3))\nplt.scatter(x=auto[\"weight\"], y=auto[\"mpg\"]);"
  },
  {
    "objectID": "Lecture7.html#linear-regression",
    "href": "Lecture7.html#linear-regression",
    "title": "Lecture 7",
    "section": "Linear Regression",
    "text": "Linear Regression\nWe can roughly estimate, i.e. “model” this relationship with a straight line:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\n\nplt.figure(figsize=(5,3))\ntmp=sns.regplot(x=auto[\"weight\"], y=auto[\"mpg\"], order=4, ci=95, \n                scatter_kws={'color':'b', 's':9}, line_kws={'color':'r'})\n\n\n\n\nRemind yourself of the definition of the slope of a straight line\n\\[\n\\beta_1 = \\frac{\\Delta y}{\\Delta x} =  \\frac{y_2-y_1}{x_2-x_1}\n\\]\n\nest = smf.ols('mpg ~ weight', auto).fit()\nest.summary().tables[1]\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n46.2165\n0.799\n57.867\n0.000\n44.646\n47.787\n\n\nweight\n-0.0076\n0.000\n-29.645\n0.000\n-0.008\n-0.007\n\n\n\n\n\n\nnp.corrcoef(auto[\"weight\"], auto[\"mpg\"])\n\narray([[ 1.        , -0.83224421],\n       [-0.83224421,  1.        ]])\n\n\n\nnp.corrcoef(auto[[\"weight\",\"mpg\", \"horsepower\"]])\n\narray([[1.        , 0.99996983, 0.99998307, ..., 0.99996685, 0.99993843,\n        0.99993167],\n       [0.99996983, 1.        , 0.9999981 , ..., 0.99987343, 0.99982207,\n        0.9998107 ],\n       [0.99998307, 0.9999981 , 1.        , ..., 0.99990253, 0.99985692,\n        0.99984671],\n       ...,\n       [0.99996685, 0.99987343, 0.99990253, ..., 1.        , 0.99999564,\n        0.99999371],\n       [0.99993843, 0.99982207, 0.99985692, ..., 0.99999564, 1.        ,\n        0.99999982],\n       [0.99993167, 0.9998107 , 0.99984671, ..., 0.99999371, 0.99999982,\n        1.        ]])\n\n\n\nFurther Reading:"
  },
  {
    "objectID": "Lab4.html",
    "href": "Lab4.html",
    "title": "Lab 4 Exercises",
    "section": "",
    "text": "More Simulations of Probabilistic Events\n\nimport numpy as np\nfrom numpy.random import default_rng\n\n\nSimulating Probabilistic Events\n\nBiased Coin: Simulate 365 days with a \\(p =\\frac{1}{4}\\) chance of being sunny (=1). Hint: exploit the fact that \\(p\\) is a fraction!\nBirthday problem Change the “birthday code” into a function with “n = number of people in a room” as an argument. (What other arguments might be useful?) Execute this function for \\(n=10, 25, 50\\).\nOverbooking flights: Imagine an airline sold \\(105\\) tickets on a flight with \\(100\\) seats. Assuming there is a \\(10\\%\\) no-show probability per passenger, “compute” (simulate) the probability that the airline will need to pay someone to not board."
  }
]